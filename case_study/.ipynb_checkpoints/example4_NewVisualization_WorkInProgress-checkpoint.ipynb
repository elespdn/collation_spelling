{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add a property to the token for normalized forms to be used not in the alignment, but for interpretation in the analysis stage and then in the visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. No normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collatex import *\n",
    "collation = Collation()\n",
    "W1 = open( \"data/example4/W1.txt\", encoding='utf-8' ).read()\n",
    "W2 = open( \"data/example4/W2.txt\", encoding='utf-8' ).read()\n",
    "W3 = open( \"data/example4/W3.txt\", encoding='utf-8' ).read()\n",
    "W4 = open( \"data/example4/W4.txt\", encoding='utf-8' ).read()\n",
    "collation.add_plain_witness( \"W1\", W1 )\n",
    "collation.add_plain_witness( \"W2\", W2 )\n",
    "collation.add_plain_witness( \"W3\", W3 )\n",
    "collation.add_plain_witness( \"W4\", W4 )\n",
    "table = collate(collation, output='html2', segmentation=False)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Dictionary\n",
    "\n",
    "This method requires the manual creation of a dictionary. In this example, the dictionary is built with **three columns**: the first for the **original form**, the second for the **normalized form** to be used during the **alignment**, the third for the **normalized form** to be used in the **interpretation**, after the alignment and before the visualisation.\n",
    "The first column must have a value, while the second and third columns may stay empty (later addition: if it's empty, does it take the t value by default???)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"table\": [[[{\"_sigil\": \"W1\", \"_token_array_position\": 0, \"n\": \"Lors\", \"p\": \"Lors\", \"t\": \"Lors \"}], null, [{\"_sigil\": \"W1\", \"_token_array_position\": 1, \"n\": \"conte\", \"p\": \"conte\", \"t\": \"conte \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 2, \"n\": \"li\", \"p\": \"li\", \"t\": \"li \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 3, \"n\": \"rois\", \"p\": \"rois\", \"t\": \"rois \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 4, \"n\": \"a\", \"p\": \"a\", \"t\": \"a \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 5, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 6, \"n\": \"reine\", \"p\": \"reine\", \"t\": \"reine \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 7, \"n\": \"coment\", \"p\": \"coment\", \"t\": \"coment \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 8, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 9, \"n\": \"dame\", \"p\": \"dame\", \"t\": \"dame \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 10, \"n\": \"del\", \"p\": \"del\", \"t\": \"del \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 11, \"n\": \"lac\", \"p\": \"lac\", \"t\": \"lac\\n\"}]], [[{\"_sigil\": \"W2\", \"_token_array_position\": 13, \"n\": \"Lors\", \"p\": \"Lors\", \"t\": \"Lors \"}], null, [{\"_sigil\": \"W2\", \"_token_array_position\": 14, \"n\": \"conte\", \"p\": \"conte\", \"t\": \"conte \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 15, \"n\": \"li\", \"p\": \"li\", \"t\": \"li \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 16, \"n\": \"rois\", \"p\": \"rois\", \"t\": \"rois \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 17, \"n\": \"a\", \"p\": \"a\", \"t\": \"a \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 18, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 19, \"n\": \"reine\", \"p\": \"reine\", \"t\": \"reine \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 20, \"n\": \"coment\", \"p\": \"coment\", \"t\": \"coment \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 21, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 22, \"n\": \"dame\", \"p\": \"dame\", \"t\": \"dame \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 23, \"n\": \"del\", \"p\": \"del\", \"t\": \"del \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 24, \"n\": \"lac\", \"p\": \"lac\", \"t\": \"lac\\n\"}]], [[{\"_sigil\": \"W3\", \"_token_array_position\": 26, \"n\": \"Lors\", \"p\": \"Lors\", \"t\": \"Lors \"}], null, [{\"_sigil\": \"W3\", \"_token_array_position\": 27, \"n\": \"conte\", \"p\": \"conte\", \"t\": \"conte \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 28, \"n\": \"li\", \"p\": \"li\", \"t\": \"li \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 29, \"n\": \"rois\", \"p\": \"rois\", \"t\": \"rois \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 30, \"n\": \"a\", \"p\": \"a\", \"t\": \"a \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 31, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 32, \"n\": \"reine\", \"p\": \"reine\", \"t\": \"roine \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 33, \"n\": \"coment\", \"p\": \"coment\", \"t\": \"coment \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 34, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 35, \"n\": \"dame\", \"p\": \"dame\", \"t\": \"dame \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 36, \"n\": \"del\", \"p\": \"del\", \"t\": \"del \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 37, \"n\": \"lac\", \"p\": \"lac\", \"t\": \"lac\\n\"}]], [[{\"_sigil\": \"W4\", \"_token_array_position\": 39, \"n\": \"Adonc\", \"p\": \"Adonc\", \"t\": \"Adonc \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 40, \"n\": \"li\", \"p\": \"li\", \"t\": \"li \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 41, \"n\": \"conte\", \"p\": \"conte\", \"t\": \"conte \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 42, \"n\": \"li\", \"p\": \"li\", \"t\": \"li \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 43, \"n\": \"rois\", \"p\": \"rois\", \"t\": \"rois \"}], null, null, null, [{\"_sigil\": \"W4\", \"_token_array_position\": 44, \"n\": \"coment\", \"p\": \"coment\", \"t\": \"comment \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 45, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 46, \"n\": \"dame\", \"p\": \"dame\", \"t\": \"dame \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 47, \"n\": \"\", \"p\": \"del\", \"t\": \"du \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 48, \"n\": \"lac\", \"p\": \"lac\", \"t\": \"lac\\n\"}]]], \"witnesses\": [\"W1\", \"W2\", \"W3\", \"W4\"]}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from collatex import *\n",
    "collation = Collation()\n",
    "\n",
    "# Create the dictionary (here 'dictionary_norm.csv') with three columns: the first for the original form (t), the second for the normalized form to be used during the alignment (n), the third for the normalized form to be used in the interpretation (p), after the alignment and before the visualisation. The first column must have a value, while the second and third columns may stay empty.\n",
    "Normit = {}\n",
    "with open('dictionary_norm.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames=['Original', 'NormalisedAlignment', 'NormalisedInterpretation'])\n",
    "    for row in reader:\n",
    "        Normit[row['Original']]= row['NormalisedAlignment']\n",
    "        \n",
    "NormitInterpretation = {}\n",
    "with open('dictionary_norm.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames=['Original', 'NormalisedAlignment', 'NormalisedInterpretation'])\n",
    "    for row in reader:\n",
    "        NormitInterpretation[row['Original']]= row['NormalisedInterpretation']\n",
    "\n",
    "from collatex.core_classes import WordPunctuationTokenizer\n",
    "tokenizer = WordPunctuationTokenizer()\n",
    "\n",
    "#read in the witnesses  from your file system \n",
    "W1 = open( \"data/example4/W1.txt\", encoding='utf-8' ).read()\n",
    "W2 = open( \"data/example4/W2.txt\", encoding='utf-8' ).read()\n",
    "W3 = open( \"data/example4/W3.txt\", encoding='utf-8' ).read()\n",
    "W4 = open( \"data/example4/W4.txt\", encoding='utf-8' ).read()\n",
    "\n",
    "# build a function to tokenize and to normalize by replace keys to be found in the dictionary by the corresponding values \n",
    "def tokennormalizer(witness) :\n",
    "    tokens_as_strings = tokenizer.tokenize(witness)\n",
    "    list = []\n",
    "    for token_string in tokens_as_strings:\n",
    "        normversion = re.sub(r'\\s+$',\"\", token_string)\n",
    "        replaceversion = Normit.get(normversion,normversion)\n",
    "        token_norm = NormitInterpretation.get(normversion,normversion)\n",
    "        list.append({'t':token_string, 'n':replaceversion, 'p':token_norm})\n",
    "    return(list)\n",
    "\n",
    "tokens_W1 = tokennormalizer(W1) \n",
    "tokens_W2 = tokennormalizer(W2) \n",
    "tokens_W3 = tokennormalizer(W3) \n",
    "tokens_W4 = tokennormalizer(W4) \n",
    "#Print to check what's in the properties; can be deleted once we can visualize it. Can check also in the collation with json output.\n",
    "##print(tokens_W1, tokens_W2, tokens_W3, tokens_W4)\n",
    " \n",
    "witness_W1 = { \"id\": \"W1\", \"tokens\":tokens_W1 }\n",
    "witness_W2 = { \"id\": \"W2\", \"tokens\":tokens_W2 }\n",
    "witness_W3 = { \"id\": \"W3\", \"tokens\":tokens_W3 }\n",
    "witness_W4 = { \"id\": \"W4\", \"tokens\":tokens_W4 }\n",
    "\n",
    "\n",
    "input = { \"witnesses\": [ witness_W1, witness_W2, witness_W3, witness_W4 ] }\n",
    "\n",
    "\n",
    "\n",
    "graph = collate(input, output='json', segmentation=False) \n",
    "print(graph)\n",
    "\n",
    "## !!! Probabilmente NON SERVONO n (normalized alignment) e p (normalized interpretation), ma solo l'originale (t) e quello normalizzato (n) bastano.\n",
    "## Ora da questo json dobbiamo tirare fuori una html table come la vogliamo noi, ovvero\n",
    "# rosso, quando n sono diversi\n",
    "# verde, quando n e t sono uguali\n",
    "# giallo, quando n sono uguali, ma t diversi\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ================= ALL THIS NOT USED ======================================\n",
    "# from the code in display module\n",
    "from collatex.HTML import Table, TableRow, TableCell\n",
    "from textwrap import fill\n",
    "\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "def visualize_table_vertically_with_colors_CUSTOM(table, collation):\n",
    "    # print the table vertically\n",
    "    # switch columns and rows\n",
    "    rows = []\n",
    "    for column in table.columns:\n",
    "        cells = []\n",
    "        for witness in collation.witnesses:\n",
    "            cell = column.tokens_per_witness.get(witness.sigil)\n",
    "            cells.append(TableCell(text=fill(\"\".join(item.token_data[\"t\"] for item in cell) if cell else \"-\", 20), bgcolor=\"FF5000\" if column.variant else \"00FFFF\"))\n",
    "        rows.append(TableRow(cells=cells))\n",
    "    sigli = []\n",
    "    \n",
    "    for witness in collation.witnesses:\n",
    "        sigli.append(witness.sigil)\n",
    "    \n",
    "    x = Table(header_row=sigli, rows=rows)\n",
    "    print(x)\n",
    "    return display(HTML(str(x)))\n",
    "\n",
    "# table = collate(input, output='table', segmentation=False) ## graph\n",
    "# visualize_table_vertically_with_colors_CUSTOM(table, collation)\n",
    "# ==========================================================================\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TEST\n",
    "\n",
    "import json\n",
    "data = json.loads(graph)\n",
    "for element in data['table']:\n",
    "    print(element)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TEST\n",
    "\n",
    "import json\n",
    "data = json.loads(graph)\n",
    "for row in data['table']:\n",
    "    print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TEST\n",
    "\n",
    "import json\n",
    "data = json.loads(graph)\n",
    "for row in data['table']:\n",
    "    for elem in row[0]: # attention, if a line with NONE it will give error\n",
    "        print(elem['t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TEST\n",
    "## Data for the header of the table\n",
    "\n",
    "# import json \n",
    "data = json.loads(graph)\n",
    "for row in data['witnesses']:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "## THIS WORKS\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "dataIn = json.loads(graph)\n",
    "\n",
    "## HEAD OF THE TABLE\n",
    "html = \"\"\"<html><table border=\"1\"><thead><tr>\"\"\"  \n",
    "for x in dataIn['table']:\n",
    "    witName = x[0][0]['_sigil']    # define the witness name\n",
    "    html += \"<th>\"+witName+\"</th>\"    # write the witness name in the head of the table\n",
    "html += \"</tr></thead><tbody>\"  ## close thead\n",
    "   \n",
    "      \n",
    "for i in range(len(x)):  # for 'i' in the length of the witness  \n",
    "    istr = str(i)   # from int to string, otherwise the following does not work\n",
    "    \n",
    "    \n",
    "    ## CREATE ROW FOR ORIGINAL TOKEN\n",
    "    html += \"<tr id='row\"+istr+\"_orig'>\"  \n",
    "    for x in dataIn['table']:   # for each witness\n",
    "        element = x[i]   # take the first, then the second, the third, etc.\n",
    "        if element is not None: \n",
    "            for elementList in element:\n",
    "                origToken = elementList['t']\n",
    "        else:\n",
    "            origToken = ' - '\n",
    "        html += \"<td>\"+origToken+\"</td>\"  # write the original token in a cell\n",
    "        ## close tbody\n",
    "    html += \"</tr>\"\n",
    "    \n",
    "    \n",
    "    ## CREATE ROW FOR NORMALIZED TOKEN\n",
    "    html += \"<tr id='row\"+istr+\"_norm'>\"  \n",
    "    for x in dataIn['table']:   # for each witness\n",
    "        element = x[i]   # take the first, then the second, the third, etc.\n",
    "        if element is not None: \n",
    "            for elementList in element:\n",
    "                normToken = elementList['n']\n",
    "        else:\n",
    "            normToken = ' - '\n",
    "        html += \"<td>\"+normToken+\"</td>\"  # write the original token in a cell\n",
    "    html += \"</tr>\"\n",
    "    \n",
    "## CLOSE BODY - END OF THE TABLE    \n",
    "html += \"</tbody>\"\n",
    "\n",
    "\n",
    "file_ = open('result2.html', 'w')\n",
    "file_.write(html)\n",
    "file_.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3696"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## As the previous, but trying to output correct attributes\n",
    "\n",
    "\n",
    "import json\n",
    "import itertools\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "\n",
    "######################################################\n",
    "##\n",
    "## BUILD HTML TABLE\n",
    "##\n",
    "######################################################\n",
    "\n",
    "dataIn = json.loads(graph)\n",
    "\n",
    "## HEAD OF THE TABLE\n",
    "html = \"\"\"<html><table border=\"1\"><thead><tr>\"\"\"  \n",
    "for x in dataIn['table']:\n",
    "    witName = x[0][0]['_sigil']    # define the witness name\n",
    "    html += \"<th>\"+witName+\"</th>\"    # write the witness name in the head of the table\n",
    "html += \"</tr></thead><tbody>\"  ## close thead\n",
    "   \n",
    "      \n",
    "for i in range(len(x)):  # for 'i' in the length of the witness  \n",
    "    istr = str(i)   # from int to string, otherwise the following does not work\n",
    "    \n",
    "    \n",
    "    ## CREATE ROW FOR ORIGINAL TOKEN\n",
    "    html += \"<tr type='orig' id='row\"+istr+\"_orig'>\"  \n",
    "    for x in dataIn['table']:   # for each witness\n",
    "        element = x[i]   # take the first (then at the next iteration take the second, etc.)\n",
    "        if element is not None: \n",
    "            for elementList in element:\n",
    "                origToken = elementList['t'].strip()  # strip used for deleting whitespaces\n",
    "        else:\n",
    "            origToken = ' - '\n",
    "        html += \"<td>\"+origToken+\"</td>\"  # write the original token in a cell\n",
    "        ## close tbody\n",
    "    html += \"</tr>\"\n",
    "    \n",
    "    ## CREATE ROW FOR NORMALIZED TOKEN (ALL) - NOT DISPLAY, just for processing\n",
    "    html += \"<tr type='normAll' id='row\"+istr+\"_normAll'>\" # style='display:none'  \n",
    "    for x in dataIn['table']:   # for each witness\n",
    "        element = x[i]   # take the first (then at the next iteration take the second, etc.)\n",
    "        if element is not None: \n",
    "            for elementList in element:\n",
    "                normCompareToken = elementList['n'].strip()  # strip used for deleting whitespaces\n",
    "        else:\n",
    "            normCompareToken = ' - '\n",
    "        html += \"<td>\"+normCompareToken+\"</td>\"  # write the original token in a cell\n",
    "        ## close tbody\n",
    "    html += \"</tr>\"\n",
    "    \n",
    "    \n",
    "    ## CREATE ROW FOR NORMALIZED TOKEN (ONLY IF DIFFERENT FROM ORIGINAL) - DISPLAY\n",
    "    html += \"<tr type='norm' id='row\"+istr+\"_norm'>\"  \n",
    "    for x in dataIn['table']:   # for each witness\n",
    "        element = x[i]   # take the first (then at the next iteration take the second, etc.)\n",
    "        if element is not None: \n",
    "            for elementList in element:\n",
    "                ## DIFFRENCE BETWEEN ORIGINAL AND NORMALIZED TOKENS\n",
    "                ## Print normalized token in new row, when different from original\n",
    "                origCompareToken = elementList['t'].strip() # strip used for deleting whitespaces\n",
    "                normCompareToken = elementList['n'].strip()\n",
    "                if normCompareToken is not None:\n",
    "                    if origCompareToken == normCompareToken:\n",
    "                        normToken = \"\"\n",
    "                    else:\n",
    "                        normToken = normCompareToken\n",
    "        else:\n",
    "            normToken = \"\" \n",
    "            normCompareToken = \"\"\n",
    "        html += \"<td>\"+normToken+\"</td>\"  # write the original token in a cell\n",
    "    html += \"</tr>\"\n",
    "    \n",
    "## CLOSE BODY - END OF THE TABLE    \n",
    "html += \"</tbody></table></html>\"\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "######################################################\n",
    "##\n",
    "## ANALYSE AND RENDER HTML TABLE\n",
    "##\n",
    "######################################################\n",
    "\n",
    "## Two classes for each row should be added: (1) if equal or different, and (2) if they include formal variation\n",
    "\n",
    "## Taken from <https://stackoverflow.com/questions/3844801/check-if-all-elements-in-a-list-are-identical>\n",
    "def checkEqual(iterator):\n",
    "   return len(set(iterator)) <= 1\n",
    "\n",
    "createdTable = html\n",
    "root = ET.fromstring(createdTable)\n",
    "for tr in root.iter('tr'):  ## iterate over rows\n",
    "    trType = tr.get('type')  # and get the value of the attribute type for each row\n",
    "    if (trType == \"normAll\"):   ## only take rows with attribute @type='normAll'\n",
    "        listTd = []   ## open empty list\n",
    "        for td in tr.iter('td'):  ## take all cells in a row\n",
    "            listTd.append(td.text)  ## and put their text in the list\n",
    "        if checkEqual(listTd) == True: ## if all the element in the list (all the aligned tokens appearing in a row) are equal\n",
    "            tr.set('class', 'invariant')  # add to the row the attribute @class=\"variant\"\n",
    "            tr.set('style', 'color:green')\n",
    "        else: \n",
    "            tr.set('class', 'variant') # add to the row the attribute @class=\"invariant\"\n",
    "            \n",
    "            tr.set('style', 'color:red')\n",
    "            \n",
    "\n",
    "tree = ET.tostring(root, encoding=\"unicode\")\n",
    "outFile = open('result2.html', 'w')\n",
    "outFile.write(tree)\n",
    "\n",
    "\n",
    "## (1)\n",
    "## PRINT \"DIFFERENT\" IF NORMALIZED IN ROW ARE DIFFERENT AND \"EQUAL\" IF NORMALIZED IN ROW ARE EQUAL\n",
    "\n",
    "## for each <tr> whose @id ends with \"norm\", if all children <td> are equal\n",
    "\n",
    "## (2) \n",
    "## If one\n",
    "\n",
    "\n",
    "# outFile = open('result2.html', 'w')\n",
    "# outFile.write(html)\n",
    "# outFile.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "false\n",
      "false\n",
      "false\n",
      "true\n",
      "false\n",
      "false\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "for a, b in itertools.combinations('ABBD', 2):\n",
    "    if a == b:\n",
    "        print(\"true\")\n",
    "    else:\n",
    "        print(\"false\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checkEqual2(iterator):\n",
    "   return len(set(iterator)) <= 1\n",
    "\n",
    "checkEqual2(['lac', 'lac', 'lec', 'lac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "equal\n"
     ]
    }
   ],
   "source": [
    "origCompareToken = 'Lors'\n",
    "normCompareToken = 'Lors'\n",
    "if origCompareToken == normCompareToken:\n",
    "    print('equal')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## DISCARDED, OTHER APPROACH USED\n",
    "## SEE FOLLOWING CELL\n",
    "\n",
    "## json used for generating idealTable.html\n",
    "\n",
    "import json\n",
    "testGraph = '''{\n",
    "\t\"table\": [\n",
    "\t\t[\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W1\",\n",
    "\t\t\t\t\"_token_array_position\": 0,\n",
    "\t\t\t\t\"n\": \"Lors\",\n",
    "\t\t\t\t\"p\": \"Lors\",\n",
    "\t\t\t\t\"t\": \"Lors \"\n",
    "\t\t\t}],\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W2\",\n",
    "\t\t\t\t\"_token_array_position\": 13,\n",
    "\t\t\t\t\"n\": \"Lors\",\n",
    "\t\t\t\t\"p\": \"Lors\",\n",
    "\t\t\t\t\"t\": \"Lors \"\n",
    "\t\t\t}],\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W3\",\n",
    "\t\t\t\t\"_token_array_position\": 26,\n",
    "\t\t\t\t\"n\": \"Lors\",\n",
    "\t\t\t\t\"p\": \"Lors\",\n",
    "\t\t\t\t\"t\": \"Lors \"\n",
    "\t\t\t}],\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W4\",\n",
    "\t\t\t\t\"_token_array_position\": 39,\n",
    "\t\t\t\t\"n\": \"Adonc\",\n",
    "\t\t\t\t\"p\": \"Adonc\",\n",
    "\t\t\t\t\"t\": \"Adonc \"\n",
    "\t\t\t}]\n",
    "\t\t],\n",
    "\t\t[\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W1\",\n",
    "\t\t\t\t\"_token_array_position\": 1,\n",
    "\t\t\t\t\"n\": \"conte\",\n",
    "\t\t\t\t\"p\": \"conte\",\n",
    "\t\t\t\t\"t\": \"conte \"\n",
    "\t\t\t}],\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W2\",\n",
    "\t\t\t\t\"_token_array_position\": 14,\n",
    "\t\t\t\t\"n\": \"conte\",\n",
    "\t\t\t\t\"p\": \"conte\",\n",
    "\t\t\t\t\"t\": \"conte \"\n",
    "\t\t\t}],\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W3\",\n",
    "\t\t\t\t\"_token_array_position\": 27,\n",
    "\t\t\t\t\"n\": \"conte\",\n",
    "\t\t\t\t\"p\": \"conte\",\n",
    "\t\t\t\t\"t\": \"conte \"\n",
    "\t\t\t}],\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W4\",\n",
    "\t\t\t\t\"_token_array_position\": 41,\n",
    "\t\t\t\t\"n\": \"conte\",\n",
    "\t\t\t\t\"p\": \"conte\",\n",
    "\t\t\t\t\"t\": \"conte \"\n",
    "\t\t\t}]\n",
    "\t\t]\n",
    "\t],\n",
    "\t\"witnesses\": [\n",
    "\t\t\"W1\",\n",
    "\t\t\"W2\",\n",
    "\t\t\"W3\",\n",
    "\t\t\"W4\"\n",
    "\t]\n",
    "}'''\n",
    "\n",
    "testData = json.loads(testGraph)\n",
    "\n",
    "print(\"DIRECT TEST:   \"+testData['table'][0][0][0]['n'])\n",
    "\n",
    "for row in testData['table']:\n",
    "    print(\"ROW\")\n",
    "    for cellList in row:\n",
    "        for cellDic in cellList:\n",
    "            print(cellDic['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## DISCARDED\n",
    "## DATA FROM PREVIOUS CELL\n",
    "\n",
    "## generating idealTable.html\n",
    "\n",
    "import json\n",
    "## open table and thead\n",
    "html = \"\"\"<html><table border=\"1\"><thead><tr>\"\"\"\n",
    "for witness in testData['witnesses']:   \n",
    "    html += \"<th>\"+witness+\"</th>\"\n",
    "## close thead\n",
    "html += \"</tr></thead>\"  \n",
    "\n",
    "## iterate over \"rows\"\n",
    "for row in testData['table']:\n",
    "    ## open tbody\n",
    "    html += \"<tbody><tr>\"\n",
    "    ## iterate over elements inside \"rows\"\n",
    "    for cellList in row:\n",
    "        for cellDic in cellList:\n",
    "            normToken = cellDic['n']\n",
    "            html += \"<td>\"+normToken+\"</td>\"\n",
    "    ## close tbody\n",
    "    html += \"</tr></tbody>\"\n",
    "file_ = open('result.html', 'w')\n",
    "file_.write(html)\n",
    "file_.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
