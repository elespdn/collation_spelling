{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add a property to the token for normalized forms to be used not in the alignment, but for interpretation in the analysis stage and then in the visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. No normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collatex import *\n",
    "collation = Collation()\n",
    "W1 = open( \"data/example4/W1.txt\", encoding='utf-8' ).read()\n",
    "W2 = open( \"data/example4/W2.txt\", encoding='utf-8' ).read()\n",
    "W3 = open( \"data/example4/W3.txt\", encoding='utf-8' ).read()\n",
    "W4 = open( \"data/example4/W4.txt\", encoding='utf-8' ).read()\n",
    "collation.add_plain_witness( \"W1\", W1 )\n",
    "collation.add_plain_witness( \"W2\", W2 )\n",
    "collation.add_plain_witness( \"W3\", W3 )\n",
    "collation.add_plain_witness( \"W4\", W4 )\n",
    "table = collate(collation, output='html2', segmentation=False)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Dictionary\n",
    "\n",
    "This method requires the manual creation of a dictionary. In this example, the dictionary is built with **three columns**: the first for the **original form**, the second for the **normalized form** to be used during the **alignment**, the third for the **normalized form** to be used in the **interpretation**, after the alignment and before the visualisation.\n",
    "The first column must have a value, while the second and third columns may stay empty (later addition: if it's empty, does it take the t value by default???)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"table\": [[[{\"_sigil\": \"W1\", \"_token_array_position\": 0, \"n\": \"Lors\", \"p\": \"Lors\", \"t\": \"Lors \"}], null, [{\"_sigil\": \"W1\", \"_token_array_position\": 1, \"n\": \"conte\", \"p\": \"conte\", \"t\": \"conte \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 2, \"n\": \"li\", \"p\": \"li\", \"t\": \"li \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 3, \"n\": \"rois\", \"p\": \"rois\", \"t\": \"rois \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 4, \"n\": \"a\", \"p\": \"a\", \"t\": \"a \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 5, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 6, \"n\": \"reine\", \"p\": \"reine\", \"t\": \"reine \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 7, \"n\": \"coment\", \"p\": \"coment\", \"t\": \"coment \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 8, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 9, \"n\": \"dame\", \"p\": \"dame\", \"t\": \"dame \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 10, \"n\": \"del\", \"p\": \"del\", \"t\": \"del \"}], [{\"_sigil\": \"W1\", \"_token_array_position\": 11, \"n\": \"lac\", \"p\": \"lac\", \"t\": \"lac\\n\"}]], [[{\"_sigil\": \"W2\", \"_token_array_position\": 13, \"n\": \"Lors\", \"p\": \"Lors\", \"t\": \"Lors \"}], null, [{\"_sigil\": \"W2\", \"_token_array_position\": 14, \"n\": \"conte\", \"p\": \"conte\", \"t\": \"conte \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 15, \"n\": \"li\", \"p\": \"li\", \"t\": \"li \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 16, \"n\": \"rois\", \"p\": \"rois\", \"t\": \"rois \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 17, \"n\": \"a\", \"p\": \"a\", \"t\": \"a \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 18, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 19, \"n\": \"reine\", \"p\": \"reine\", \"t\": \"reine \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 20, \"n\": \"coment\", \"p\": \"coment\", \"t\": \"coment \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 21, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 22, \"n\": \"dame\", \"p\": \"dame\", \"t\": \"dame \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 23, \"n\": \"del\", \"p\": \"del\", \"t\": \"del \"}], [{\"_sigil\": \"W2\", \"_token_array_position\": 24, \"n\": \"lac\", \"p\": \"lac\", \"t\": \"lac\\n\"}]], [[{\"_sigil\": \"W3\", \"_token_array_position\": 26, \"n\": \"Lors\", \"p\": \"Lors\", \"t\": \"Lors \"}], null, [{\"_sigil\": \"W3\", \"_token_array_position\": 27, \"n\": \"conte\", \"p\": \"conte\", \"t\": \"conte \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 28, \"n\": \"li\", \"p\": \"li\", \"t\": \"li \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 29, \"n\": \"rois\", \"p\": \"rois\", \"t\": \"rois \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 30, \"n\": \"a\", \"p\": \"a\", \"t\": \"a \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 31, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 32, \"n\": \"reine\", \"p\": \"reine\", \"t\": \"roine \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 33, \"n\": \"coment\", \"p\": \"coment\", \"t\": \"coment \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 34, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 35, \"n\": \"dame\", \"p\": \"dame\", \"t\": \"dame \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 36, \"n\": \"del\", \"p\": \"del\", \"t\": \"del \"}], [{\"_sigil\": \"W3\", \"_token_array_position\": 37, \"n\": \"lac\", \"p\": \"lac\", \"t\": \"lac\\n\"}]], [[{\"_sigil\": \"W4\", \"_token_array_position\": 39, \"n\": \"Adonc\", \"p\": \"Adonc\", \"t\": \"Adonc \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 40, \"n\": \"li\", \"p\": \"li\", \"t\": \"li \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 41, \"n\": \"conte\", \"p\": \"conte\", \"t\": \"conte \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 42, \"n\": \"li\", \"p\": \"li\", \"t\": \"li \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 43, \"n\": \"rois\", \"p\": \"rois\", \"t\": \"rois \"}], null, null, null, [{\"_sigil\": \"W4\", \"_token_array_position\": 44, \"n\": \"coment\", \"p\": \"coment\", \"t\": \"comment \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 45, \"n\": \"la\", \"p\": \"la\", \"t\": \"la \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 46, \"n\": \"dame\", \"p\": \"dame\", \"t\": \"dame \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 47, \"n\": \"del\", \"p\": \"del\", \"t\": \"du \"}], [{\"_sigil\": \"W4\", \"_token_array_position\": 48, \"n\": \"lac\", \"p\": \"lac\", \"t\": \"lac\\n\"}]]], \"witnesses\": [\"W1\", \"W2\", \"W3\", \"W4\"]}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "from collatex import *\n",
    "collation = Collation()\n",
    "\n",
    "# Create the dictionary (here 'dictionary_norm.csv') with three columns: the first for the original form (t), the second for the normalized form to be used during the alignment (n), the third for the normalized form to be used in the interpretation (p), after the alignment and before the visualisation. The first column must have a value, while the second and third columns may stay empty.\n",
    "Normit = {}\n",
    "with open('dictionary_norm.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames=['Original', 'NormalisedAlignment', 'NormalisedInterpretation'])\n",
    "    for row in reader:\n",
    "        Normit[row['Original']]= row['NormalisedAlignment']\n",
    "        \n",
    "NormitInterpretation = {}\n",
    "with open('dictionary_norm.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames=['Original', 'NormalisedAlignment', 'NormalisedInterpretation'])\n",
    "    for row in reader:\n",
    "        NormitInterpretation[row['Original']]= row['NormalisedInterpretation']\n",
    "\n",
    "from collatex.core_classes import WordPunctuationTokenizer\n",
    "tokenizer = WordPunctuationTokenizer()\n",
    "\n",
    "#read in the witnesses  from your file system \n",
    "W1 = open( \"data/example4/W1.txt\", encoding='utf-8' ).read()\n",
    "W2 = open( \"data/example4/W2.txt\", encoding='utf-8' ).read()\n",
    "W3 = open( \"data/example4/W3.txt\", encoding='utf-8' ).read()\n",
    "W4 = open( \"data/example4/W4.txt\", encoding='utf-8' ).read()\n",
    "\n",
    "# build a function to tokenize and to normalize by replace keys to be found in the dictionary by the corresponding values \n",
    "def tokennormalizer(witness) :\n",
    "    tokens_as_strings = tokenizer.tokenize(witness)\n",
    "    list = []\n",
    "    for token_string in tokens_as_strings:\n",
    "        normversion = re.sub(r'\\s+$',\"\", token_string)\n",
    "        replaceversion = Normit.get(normversion,normversion)\n",
    "        token_norm = NormitInterpretation.get(normversion,normversion)\n",
    "        list.append({'t':token_string, 'n':replaceversion, 'p':token_norm})\n",
    "    return(list)\n",
    "\n",
    "tokens_W1 = tokennormalizer(W1) \n",
    "tokens_W2 = tokennormalizer(W2) \n",
    "tokens_W3 = tokennormalizer(W3) \n",
    "tokens_W4 = tokennormalizer(W4) \n",
    "#Print to check what's in the properties; can be deleted once we can visualize it. Can check also in the collation with json output.\n",
    "##print(tokens_W1, tokens_W2, tokens_W3, tokens_W4)\n",
    " \n",
    "witness_W1 = { \"id\": \"W1\", \"tokens\":tokens_W1 }\n",
    "witness_W2 = { \"id\": \"W2\", \"tokens\":tokens_W2 }\n",
    "witness_W3 = { \"id\": \"W3\", \"tokens\":tokens_W3 }\n",
    "witness_W4 = { \"id\": \"W4\", \"tokens\":tokens_W4 }\n",
    "\n",
    "\n",
    "input = { \"witnesses\": [ witness_W1, witness_W2, witness_W3, witness_W4 ] }\n",
    "\n",
    "\n",
    "\n",
    "graph = collate(input, output='json', segmentation=False) \n",
    "print(graph)\n",
    "\n",
    "## !!! Probabilmente NON SERVONO n (normalized alignment) e p (normalized interpretation), ma solo l'originale (t) e quello normalizzato (n) bastano.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4213"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "            #====================================================#\n",
    "            #====================================================#\n",
    "            #                                                    #\n",
    "            #   CREATE TABLE FROM JSON USING NORMALIZED TOKENS   #\n",
    "            #                                                    # \n",
    "            #====================================================#\n",
    "            #====================================================#\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "import json\n",
    "import itertools\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "\n",
    "#====================================================\n",
    "#\n",
    "#  BUILD HTML TABLE\n",
    "#\n",
    "#====================================================\n",
    "\n",
    "dataIn = json.loads(graph)\n",
    "\n",
    "## HEAD OF THE TABLE\n",
    "\n",
    "# there is an x inside the script pointing to jquery because if it's empty it will \n",
    "# automatically be written as a closed empty tag in the output and would not work\n",
    "html = \"\"\"<html>\n",
    "    <head>\n",
    "\t<title>Test collation with normalized tokens</title>\n",
    "\t<script src=\"https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js\">x</script>\n",
    "\t<script type=\"text/javascript\">  \n",
    "            $(document).ready(function(){\n",
    "                $(\"tr[type='orig']\").click(function(){\n",
    "                    $(this).next().toggle();\n",
    "                });\n",
    "            });\n",
    "    </script>\n",
    "\t<style>\n",
    "         tr[type=\"normAll\"] {display: none;}\n",
    "         tr[type=\"norm\"] {display: none;}\n",
    "         td, th {padding: 20px;border: 1px solid grey; width:100px}\n",
    "         table {border-collapse: collapse;}\n",
    "         .variant + tr {background-color:#06e089}\n",
    "         .invariant + tr {background-color:lightgray}\n",
    "    </style>\n",
    "\t</head>\"\"\"\n",
    "\n",
    "html += \"\"\"<body><table border=\"1\"><thead><tr>\"\"\"  \n",
    "for x in dataIn['table']:\n",
    "    witName = x[0][0]['_sigil']    # define the witness name\n",
    "    html += \"<th>\"+witName+\"</th>\"    # write the witness name in the head of the table\n",
    "html += \"</tr></thead><tbody>\"  ## close thead\n",
    "   \n",
    "      \n",
    "for i in range(len(x)):  # for 'i' in the length of the witness  \n",
    "    istr = str(i)   # from int to string, otherwise the following does not work\n",
    "    \n",
    "    ## CREATE ROW FOR NORMALIZED TOKEN (ALL) - NOT DISPLAY, just for processing\n",
    "    html += \"<tr type='normAll' id='row\"+istr+\"_normAll'>\" # style='display:none'  \n",
    "    for x in dataIn['table']:   # for each witness\n",
    "        element = x[i]   # take the first (then at the next iteration take the second, etc.)\n",
    "        if element is not None: \n",
    "            for elementList in element:\n",
    "                normCompareToken = elementList['n'].strip()  # strip used for deleting whitespaces\n",
    "        else:\n",
    "            normCompareToken = ' - '\n",
    "        html += \"<td>\"+normCompareToken+\"</td>\"  # write the original token in a cell\n",
    "        ## close tbody\n",
    "    html += \"</tr>\"\n",
    "    \n",
    "    \n",
    "    ## CREATE ROW FOR ORIGINAL TOKEN\n",
    "    html += \"<tr type='orig' id='row\"+istr+\"_orig'>\"  \n",
    "    for x in dataIn['table']:   # for each witness\n",
    "        element = x[i]   # take the first (then at the next iteration take the second, etc.)\n",
    "        if element is not None: \n",
    "            for elementList in element:\n",
    "                origToken = elementList['t'].strip()  # strip used for deleting whitespaces\n",
    "                normCompareToken = elementList['n'].strip()\n",
    "                if normCompareToken is not None:\n",
    "                    if origToken != normCompareToken:\n",
    "                        origToken = \"<u>\"+origToken+\"</u>\"\n",
    "                    else:\n",
    "                        origToken = origToken\n",
    "        else:\n",
    "            origToken = ' - '\n",
    "        html += \"<td>\"+origToken+\"</td>\"  # write the original token in a cell\n",
    "        ## close tbody\n",
    "    html += \"</tr>\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    ## CREATE ROW FOR NORMALIZED TOKEN (ONLY IF DIFFERENT FROM ORIGINAL) - DISPLAY\n",
    "    html += \"<tr type='norm' id='row\"+istr+\"_norm'>\"  \n",
    "    for x in dataIn['table']:   # for each witness\n",
    "        element = x[i]   # take the first (then at the next iteration take the second, etc.)\n",
    "        if element is not None: \n",
    "            for elementList in element:\n",
    "                ## DIFFRENCE BETWEEN ORIGINAL AND NORMALIZED TOKENS\n",
    "                ## Print normalized token in new row, when different from original\n",
    "                origCompareToken = elementList['t'].strip() # strip used for deleting whitespaces\n",
    "                normCompareToken = elementList['n'].strip()\n",
    "                if normCompareToken is not None:\n",
    "                    if origCompareToken == normCompareToken:\n",
    "                        normToken = \"\"\n",
    "                    else:\n",
    "                        normToken = normCompareToken\n",
    "        else:\n",
    "            normToken = \"\" \n",
    "            normCompareToken = \"\"\n",
    "        html += \"<td>\"+normToken+\"</td>\"  # write the original token in a cell\n",
    "    html += \"</tr>\"\n",
    "    \n",
    "## CLOSE BODY - END OF THE TABLE    \n",
    "html += \"</tbody></table></body></html>\"\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "#====================================================\n",
    "#\n",
    "#  ANALYSE AND RENDER HTML TABLE\n",
    "#\n",
    "#====================================================\n",
    "\n",
    "## Two classes for each row should be added: (1) if equal or different, and (2) if they include formal variation\n",
    "\n",
    "## Taken from <https://stackoverflow.com/questions/3844801/check-if-all-elements-in-a-list-are-identical>\n",
    "def checkEqual(iterator):\n",
    "   return len(set(iterator)) <= 1\n",
    "\n",
    "createdTable = html\n",
    "root = ET.fromstring(createdTable)\n",
    "for tr in root.iter('tr'):  ## iterate over rows\n",
    "    trType = tr.get('type')  # and get the value of the attribute type for each row\n",
    "    if (trType == \"normAll\"):   ## only take rows with attribute @type='normAll'\n",
    "        listTd = []   ## open empty list\n",
    "        for td in tr.iter('td'):  ## take all cells in a row\n",
    "            listTd.append(td.text)  ## and put their text in the list\n",
    "        if checkEqual(listTd) == True: ## if all the element in the list (all the aligned tokens appearing in a row) are equal\n",
    "            tr.set('class', 'invariant')  # add to the row the attribute @class=\"variant\"\n",
    "            # tr.set('style', 'color:green')\n",
    "        else: \n",
    "            tr.set('class', 'variant') # add to the row the attribute @class=\"invariant\"\n",
    "            # tr.set('style', 'color:red')\n",
    "            \n",
    "\n",
    "tree = ET.tostring(root, encoding=\"unicode\")\n",
    "outFile = open('result2.html', 'w')\n",
    "outFile.write(tree)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TEI><app id='app_0'><rdg with='W1' ana='Lors'>Lors</rdg><rdg with='W2' ana='Lors'>Lors</rdg><rdg with='W3' ana='Lors'>Lors</rdg><rdg with='W4' ana='Adonc'>Adonc</rdg></app><app id='app_1'><rdg with='W4' ana='li'>li</rdg></app><app id='app_2'><rdg with='W1' ana='conte'>conte</rdg><rdg with='W2' ana='conte'>conte</rdg><rdg with='W3' ana='conte'>conte</rdg><rdg with='W4' ana='conte'>conte</rdg></app><app id='app_3'><rdg with='W1' ana='li'>li</rdg><rdg with='W2' ana='li'>li</rdg><rdg with='W3' ana='li'>li</rdg><rdg with='W4' ana='li'>li</rdg></app><app id='app_4'><rdg with='W1' ana='rois'>rois</rdg><rdg with='W2' ana='rois'>rois</rdg><rdg with='W3' ana='rois'>rois</rdg><rdg with='W4' ana='rois'>rois</rdg></app><app id='app_5'><rdg with='W1' ana='a'>a</rdg><rdg with='W2' ana='a'>a</rdg><rdg with='W3' ana='a'>a</rdg></app><app id='app_6'><rdg with='W1' ana='la'>la</rdg><rdg with='W2' ana='la'>la</rdg><rdg with='W3' ana='la'>la</rdg></app><app id='app_7'><rdg with='W1' ana='reine'>reine</rdg><rdg with='W2' ana='reine'>reine</rdg><rdg with='W3' ana='reine'>roine</rdg></app><app id='app_8'><rdg with='W1' ana='coment'>coment</rdg><rdg with='W2' ana='coment'>coment</rdg><rdg with='W3' ana='coment'>coment</rdg><rdg with='W4' ana='coment'>comment</rdg></app><app id='app_9'><rdg with='W1' ana='la'>la</rdg><rdg with='W2' ana='la'>la</rdg><rdg with='W3' ana='la'>la</rdg><rdg with='W4' ana='la'>la</rdg></app><app id='app_10'><rdg with='W1' ana='dame'>dame</rdg><rdg with='W2' ana='dame'>dame</rdg><rdg with='W3' ana='dame'>dame</rdg><rdg with='W4' ana='dame'>dame</rdg></app><app id='app_11'><rdg with='W1' ana='del'>del</rdg><rdg with='W2' ana='del'>del</rdg><rdg with='W3' ana='del'>del</rdg><rdg with='W4' ana='del'>du</rdg></app><app id='app_12'><rdg with='W1' ana='lac'>lac</rdg><rdg with='W2' ana='lac'>lac</rdg><rdg with='W3' ana='lac'>lac</rdg><rdg with='W4' ana='lac'>lac</rdg></app></TEI>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "            #======================================================#\n",
    "            #======================================================#\n",
    "            #                                                      #\n",
    "            #   SIMPLE TEI OUTPUT   (no analysis                   #\n",
    "            #                                                      # \n",
    "            #======================================================#\n",
    "            #======================================================#\n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "#====================================================\n",
    "#\n",
    "#  BUILD APPARATUS\n",
    "#\n",
    "#====================================================\n",
    "\n",
    "import json\n",
    "# read data\n",
    "dataIn = json.loads(graph)\n",
    "\n",
    "\n",
    "# opening file\n",
    "tei = \"\"\"<TEI>\"\"\"  \n",
    "  \n",
    "for x in dataIn['table']:\n",
    "    pass\n",
    " \n",
    "for i in range(len(x)):  # for 'i' in the length of the witness  \n",
    "    istr = str(i)   # from int to string, otherwise the following does not work\n",
    "\n",
    "    ## CREATE APP AND RDGs\n",
    "    tei += \"<app id='app_\"+istr+\"'>\"  \n",
    "    for x in dataIn['table']:   # for each witness\n",
    "        element = x[i]   # take the first (then at the next iteration take the second, etc.)\n",
    "        if element is not None: \n",
    "            for elementList in element:\n",
    "                sigil = elementList['_sigil'].strip()\n",
    "                origToken = elementList['t'].strip()\n",
    "                normToken = elementList['n'].strip()\n",
    "        else:\n",
    "            origToken = \"\"\n",
    "            normToken = \"\" \n",
    "        if origToken == \"\":\n",
    "            pass\n",
    "        else:\n",
    "            if normToken == \"\":\n",
    "                tei += \"<rdg with='\"+sigil+\"'>\"+origToken+\"</rdg>\" \n",
    "            else:\n",
    "                tei += \"<rdg with='\"+sigil+\"' ana='\"+normToken+\"'>\"+origToken+\"</rdg>\"  # write the original token in a cell\n",
    "    tei += \"</app>\"\n",
    "    \n",
    "## CLOSing of the file   \n",
    "tei += \"</TEI>\"\n",
    "\n",
    "print(tei)\n",
    "\n",
    "\n",
    "file_ = open('result_TEI.xml', 'w')\n",
    "file_.write(tei)\n",
    "file_.close()\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TEI><app class=\"variant\" id=\"app_0\"><rdg ana=\"Lors\" with=\"W1\">Lors</rdg><rdg ana=\"Lors\" with=\"W2\">Lors</rdg><rdg ana=\"Lors\" with=\"W3\">Lors</rdg><rdg ana=\"Adonc\" with=\"W4\">Adonc</rdg></app><app class=\"invariant\" id=\"app_1\"><rdg ana=\"li\" with=\"W4\">li</rdg></app><app class=\"invariant\" id=\"app_2\"><rdg ana=\"conte\" with=\"W1\">conte</rdg><rdg ana=\"conte\" with=\"W2\">conte</rdg><rdg ana=\"conte\" with=\"W3\">conte</rdg><rdg ana=\"conte\" with=\"W4\">conte</rdg></app><app class=\"invariant\" id=\"app_3\"><rdg ana=\"li\" with=\"W1\">li</rdg><rdg ana=\"li\" with=\"W2\">li</rdg><rdg ana=\"li\" with=\"W3\">li</rdg><rdg ana=\"li\" with=\"W4\">li</rdg></app><app class=\"invariant\" id=\"app_4\"><rdg ana=\"rois\" with=\"W1\">rois</rdg><rdg ana=\"rois\" with=\"W2\">rois</rdg><rdg ana=\"rois\" with=\"W3\">rois</rdg><rdg ana=\"rois\" with=\"W4\">rois</rdg></app><app class=\"invariant\" id=\"app_5\"><rdg ana=\"a\" with=\"W1\">a</rdg><rdg ana=\"a\" with=\"W2\">a</rdg><rdg ana=\"a\" with=\"W3\">a</rdg></app><app class=\"invariant\" id=\"app_6\"><rdg ana=\"la\" with=\"W1\">la</rdg><rdg ana=\"la\" with=\"W2\">la</rdg><rdg ana=\"la\" with=\"W3\">la</rdg></app><app class=\"variant\" id=\"app_7\"><rdg ana=\"reine\" with=\"W1\">reine</rdg><rdg ana=\"reine\" with=\"W2\">reine</rdg><rdg ana=\"reine\" with=\"W3\">roine</rdg></app><app class=\"variant\" id=\"app_8\"><rdg ana=\"coment\" with=\"W1\">coment</rdg><rdg ana=\"coment\" with=\"W2\">coment</rdg><rdg ana=\"coment\" with=\"W3\">coment</rdg><rdg ana=\"coment\" with=\"W4\">comment</rdg></app><app class=\"invariant\" id=\"app_9\"><rdg ana=\"la\" with=\"W1\">la</rdg><rdg ana=\"la\" with=\"W2\">la</rdg><rdg ana=\"la\" with=\"W3\">la</rdg><rdg ana=\"la\" with=\"W4\">la</rdg></app><app class=\"invariant\" id=\"app_10\"><rdg ana=\"dame\" with=\"W1\">dame</rdg><rdg ana=\"dame\" with=\"W2\">dame</rdg><rdg ana=\"dame\" with=\"W3\">dame</rdg><rdg ana=\"dame\" with=\"W4\">dame</rdg></app><app class=\"variant\" id=\"app_11\"><rdg ana=\"del\" with=\"W1\">del</rdg><rdg ana=\"del\" with=\"W2\">del</rdg><rdg ana=\"del\" with=\"W3\">del</rdg><rdg ana=\"del\" with=\"W4\">du</rdg></app><app class=\"invariant\" id=\"app_12\"><rdg ana=\"lac\" with=\"W1\">lac</rdg><rdg ana=\"lac\" with=\"W2\">lac</rdg><rdg ana=\"lac\" with=\"W3\">lac</rdg><rdg ana=\"lac\" with=\"W4\">lac</rdg></app></TEI>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2132"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "            #======================================================#\n",
    "            #======================================================#\n",
    "            #                                                      #\n",
    "            #   COMPLETE TEI OUTPUT   (with analysis)              #\n",
    "            #                                                      # \n",
    "            #======================================================#\n",
    "            #======================================================#\n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "## create rdgGrp with attribute for formal variants\n",
    "## add attribute to substantial variant? If normCompare are not equal or not all\n",
    "\n",
    "        \n",
    "        \n",
    "import json\n",
    "from xml.etree import ElementTree as ET\n",
    "\n",
    "\n",
    "#====================================================\n",
    "#\n",
    "#  BUILD APPARATUS\n",
    "#\n",
    "#====================================================\n",
    "\n",
    "\n",
    "# read data\n",
    "dataIn = json.loads(graph)\n",
    "\n",
    "\n",
    "# open file\n",
    "tei = \"\"\"<TEI>\"\"\"  \n",
    "# CREATE APP AND RDGs\n",
    "for i in range(len(witness)):  # for 'i' in the length of the witness  \n",
    "    istr = str(i)   # from int to string, for adding it later to attribute\n",
    "    tei += \"<app id='app_\"+istr+\"'>\"  \n",
    "    for x in dataIn['table']:   # for each witness\n",
    "        element = x[i]   # take the first (then at the next iteration take the second, etc.)\n",
    "        if element is not None: \n",
    "            for elementList in element:\n",
    "                sigil = elementList['_sigil'].strip()\n",
    "                origToken = elementList['t'].strip()\n",
    "                normToken = elementList['n'].strip()\n",
    "        else:\n",
    "            origToken = \"\"\n",
    "            normToken = \"\" \n",
    "        if origToken == \"\":\n",
    "            pass\n",
    "        else:\n",
    "            if normToken == \"\":\n",
    "                tei += \"<rdg with='\"+sigil+\"'>\"+origToken+\"</rdg>\" \n",
    "            else:\n",
    "                tei += \"<rdg with='\"+sigil+\"' ana='\"+normToken+\"'>\"+origToken+\"</rdg>\"  # write the original token in a cell\n",
    "    tei += \"</app>\"\n",
    "    \n",
    "## CLOSE file \n",
    "tei += \"</TEI>\"\n",
    "\n",
    "\n",
    "# count the number of witnesses\n",
    "allWitnesses = []\n",
    "for witness in dataIn['table']:\n",
    "    allWitnesses.append(witness)\n",
    "numberOfWitnesses = len(allWitnesses)\n",
    "\n",
    "\n",
    "\n",
    "#====================================================\n",
    "#\n",
    "#  ANALYSE AND RENDER HTML TABLE\n",
    "#\n",
    "#====================================================\n",
    "\n",
    "## Two classes for each row should be added: (1) if equal or different, and (2) if they include formal variation\n",
    "\n",
    "## Taken from <https://stackoverflow.com/questions/3844801/check-if-all-elements-in-a-list-are-identical>\n",
    "def checkEqual(iterator):\n",
    "   return len(set(iterator)) <= 1\n",
    "\n",
    "root = ET.fromstring(tei)\n",
    "for app in root.iter('app'):  ## iterate over rows\n",
    "    normalizedTokensAligned = []\n",
    "    for rdg in app.iter('rdg'):  ## take all cells in a row\n",
    "            normalizedTokensAligned.append(rdg.text)  ## and put their text in the list\n",
    "    if checkEqual(normalizedTokensAligned) == True: ## if all the element in the list (all the aligned tokens appearing in a row) are equal\n",
    "        app.set('class', 'invariant')  # add to the row the attribute @class=\"variant\"\n",
    "        # tr.set('style', 'color:green')\n",
    "    else: \n",
    "        app.set('class', 'variant') # add to the row the attribute @class=\"invariant\"\n",
    "        # tr.set('style', 'color:red')\n",
    "            \n",
    "tree = ET.tostring(root, encoding=\"unicode\")\n",
    "print(tree)\n",
    "\n",
    "outFile = open('result_TEIcomplete.xml', 'w')\n",
    "outFile.write(tree)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SIMPLER VERSION OF THE PREVIOUS, obsolete now\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "dataIn = json.loads(graph)\n",
    "\n",
    "## HEAD OF THE TABLE\n",
    "html = \"\"\"<html><table border=\"1\"><thead><tr>\"\"\"  \n",
    "for x in dataIn['table']:\n",
    "    witName = x[0][0]['_sigil']    # define the witness name\n",
    "    html += \"<th>\"+witName+\"</th>\"    # write the witness name in the head of the table\n",
    "html += \"</tr></thead><tbody>\"  ## close thead\n",
    "   \n",
    "      \n",
    "for i in range(len(x)):  # for 'i' in the length of the witness  \n",
    "    istr = str(i)   # from int to string, otherwise the following does not work\n",
    "    \n",
    "    \n",
    "    ## CREATE ROW FOR ORIGINAL TOKEN\n",
    "    html += \"<tr id='row\"+istr+\"_orig'>\"  \n",
    "    for x in dataIn['table']:   # for each witness\n",
    "        element = x[i]   # take the first, then the second, the third, etc.\n",
    "        if element is not None: \n",
    "            for elementList in element:\n",
    "                origToken = elementList['t']\n",
    "        else:\n",
    "            origToken = ' - '\n",
    "        html += \"<td>\"+origToken+\"</td>\"  # write the original token in a cell\n",
    "        ## close tbody\n",
    "    html += \"</tr>\"\n",
    "    \n",
    "    \n",
    "    ## CREATE ROW FOR NORMALIZED TOKEN\n",
    "    html += \"<tr id='row\"+istr+\"_norm'>\"  \n",
    "    for x in dataIn['table']:   # for each witness\n",
    "        element = x[i]   # take the first, then the second, the third, etc.\n",
    "        if element is not None: \n",
    "            for elementList in element:\n",
    "                normToken = elementList['n']\n",
    "        else:\n",
    "            normToken = ' - '\n",
    "        html += \"<td>\"+normToken+\"</td>\"  # write the original token in a cell\n",
    "    html += \"</tr>\"\n",
    "    \n",
    "## CLOSE BODY - END OF THE TABLE    \n",
    "html += \"</tbody>\"\n",
    "\n",
    "\n",
    "file_ = open('result2.html', 'w')\n",
    "file_.write(html)\n",
    "file_.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def checkEqual2(iterator):\n",
    "   return len(set(iterator)) <= 1\n",
    "\n",
    "checkEqual2(['lac', 'lac', 'lec', 'lac'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TEST\n",
    "\n",
    "import json\n",
    "data = json.loads(graph)\n",
    "for row in data['table']:\n",
    "    print(row[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TEST\n",
    "\n",
    "import json\n",
    "data = json.loads(graph)\n",
    "for row in data['table']:\n",
    "    for elem in row[0]: # attention, if a line with NONE it will give error\n",
    "        print(elem['t'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TEST\n",
    "## Data for the header of the table\n",
    "\n",
    "# import json \n",
    "data = json.loads(graph)\n",
    "for row in data['witnesses']:\n",
    "    print(row)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## DISCARDED, OTHER APPROACH USED\n",
    "## SEE FOLLOWING CELL\n",
    "\n",
    "## json used for generating idealTable.html\n",
    "\n",
    "import json\n",
    "testGraph = '''{\n",
    "\t\"table\": [\n",
    "\t\t[\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W1\",\n",
    "\t\t\t\t\"_token_array_position\": 0,\n",
    "\t\t\t\t\"n\": \"Lors\",\n",
    "\t\t\t\t\"p\": \"Lors\",\n",
    "\t\t\t\t\"t\": \"Lors \"\n",
    "\t\t\t}],\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W2\",\n",
    "\t\t\t\t\"_token_array_position\": 13,\n",
    "\t\t\t\t\"n\": \"Lors\",\n",
    "\t\t\t\t\"p\": \"Lors\",\n",
    "\t\t\t\t\"t\": \"Lors \"\n",
    "\t\t\t}],\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W3\",\n",
    "\t\t\t\t\"_token_array_position\": 26,\n",
    "\t\t\t\t\"n\": \"Lors\",\n",
    "\t\t\t\t\"p\": \"Lors\",\n",
    "\t\t\t\t\"t\": \"Lors \"\n",
    "\t\t\t}],\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W4\",\n",
    "\t\t\t\t\"_token_array_position\": 39,\n",
    "\t\t\t\t\"n\": \"Adonc\",\n",
    "\t\t\t\t\"p\": \"Adonc\",\n",
    "\t\t\t\t\"t\": \"Adonc \"\n",
    "\t\t\t}]\n",
    "\t\t],\n",
    "\t\t[\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W1\",\n",
    "\t\t\t\t\"_token_array_position\": 1,\n",
    "\t\t\t\t\"n\": \"conte\",\n",
    "\t\t\t\t\"p\": \"conte\",\n",
    "\t\t\t\t\"t\": \"conte \"\n",
    "\t\t\t}],\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W2\",\n",
    "\t\t\t\t\"_token_array_position\": 14,\n",
    "\t\t\t\t\"n\": \"conte\",\n",
    "\t\t\t\t\"p\": \"conte\",\n",
    "\t\t\t\t\"t\": \"conte \"\n",
    "\t\t\t}],\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W3\",\n",
    "\t\t\t\t\"_token_array_position\": 27,\n",
    "\t\t\t\t\"n\": \"conte\",\n",
    "\t\t\t\t\"p\": \"conte\",\n",
    "\t\t\t\t\"t\": \"conte \"\n",
    "\t\t\t}],\n",
    "\t\t\t[{\n",
    "\t\t\t\t\"_sigil\": \"W4\",\n",
    "\t\t\t\t\"_token_array_position\": 41,\n",
    "\t\t\t\t\"n\": \"conte\",\n",
    "\t\t\t\t\"p\": \"conte\",\n",
    "\t\t\t\t\"t\": \"conte \"\n",
    "\t\t\t}]\n",
    "\t\t]\n",
    "\t],\n",
    "\t\"witnesses\": [\n",
    "\t\t\"W1\",\n",
    "\t\t\"W2\",\n",
    "\t\t\"W3\",\n",
    "\t\t\"W4\"\n",
    "\t]\n",
    "}'''\n",
    "\n",
    "testData = json.loads(testGraph)\n",
    "\n",
    "print(\"DIRECT TEST:   \"+testData['table'][0][0][0]['n'])\n",
    "\n",
    "for row in testData['table']:\n",
    "    print(\"ROW\")\n",
    "    for cellList in row:\n",
    "        for cellDic in cellList:\n",
    "            print(cellDic['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## DISCARDED\n",
    "## DATA FROM PREVIOUS CELL\n",
    "\n",
    "## generating idealTable.html\n",
    "\n",
    "import json\n",
    "## open table and thead\n",
    "html = \"\"\"<html><table border=\"1\"><thead><tr>\"\"\"\n",
    "for witness in testData['witnesses']:   \n",
    "    html += \"<th>\"+witness+\"</th>\"\n",
    "## close thead\n",
    "html += \"</tr></thead>\"  \n",
    "\n",
    "## iterate over \"rows\"\n",
    "for row in testData['table']:\n",
    "    ## open tbody\n",
    "    html += \"<tbody><tr>\"\n",
    "    ## iterate over elements inside \"rows\"\n",
    "    for cellList in row:\n",
    "        for cellDic in cellList:\n",
    "            normToken = cellDic['n']\n",
    "            html += \"<td>\"+normToken+\"</td>\"\n",
    "    ## close tbody\n",
    "    html += \"</tr></tbody>\"\n",
    "file_ = open('result.html', 'w')\n",
    "file_.write(html)\n",
    "file_.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
