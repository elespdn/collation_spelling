{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Example 1\n",
    "\n",
    "La belle au bois dormant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Automatic dictionary (table and graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method creates a dictionary, using the [TreeTagger](http://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/) parameters for French.\n",
    "\n",
    "The tagged forms are used for the alignment.\n",
    "\n",
    "This method produces three outputs:\n",
    "- a table and a graph, for which see below here; \n",
    "- an external table, where formal and substantive variants are separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f0e66148fd84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtag_poslemma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'example1'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# ex: create_poslemma('example1')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"taggedAll and taggedDistinct created in folder Dictionaries/ !\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/elespdn/collation_spelling/case_study_FR-MOD/general_functions.py\u001b[0m in \u001b[0;36mtag_poslemma\u001b[0;34m(dirName)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Original'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Normalised'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from collatex import *\n",
    "collation = Collation()\n",
    "import csv, re\n",
    "from general_functions import tag_poslemma\n",
    "from general_functions import table_automaticDictionary\n",
    "\n",
    "\n",
    "\n",
    "tag_poslemma('example1')  # ex: create_poslemma('example1')\n",
    "print(\"taggedAll and taggedDistinct created in folder Dictionaries/ !\")\n",
    "\n",
    "\n",
    "W1 = open( \"data/example1/W1.txt\", encoding='utf-8' ).read()\n",
    "W2 = open( \"data/example1/W2.txt\", encoding='utf-8' ).read()\n",
    "\n",
    "Normit = {}\n",
    "with open('dictionaries/taggedAll_example1.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, fieldnames=['Original', 'Normalised'])\n",
    "    for row in reader:\n",
    "        Normit[row['Original']]= row['Normalised']\n",
    "\n",
    "#read in the witnesses  from your file system \n",
    "from collatex.core_classes import WordPunctuationTokenizer\n",
    "tokenizer = WordPunctuationTokenizer()\n",
    "\n",
    "# build a function to tokenize and to normalize by replace keys to be \n",
    "# found in the dictionary by the corresponding values \n",
    "def tokennormalizer(witness) :\n",
    "    tokens_as_strings = tokenizer.tokenize(witness)\n",
    "    list = []\n",
    "    for token_string in tokens_as_strings:\n",
    "        normversion = re.sub(r'\\s+$',\"\", token_string)\n",
    "        replaceversion = Normit.get(normversion,normversion)\n",
    "        list.append({'t':token_string, 'n':replaceversion})\n",
    "    return(list)\n",
    "\n",
    "#collate\n",
    "tokens_W1 = tokennormalizer(W1) \n",
    "tokens_W2 = tokennormalizer(W2) \n",
    "\n",
    "witness_W1 = { \"id\": \"W1\", \"tokens\":tokens_W1 }\n",
    "witness_W2 = { \"id\": \"W2\", \"tokens\":tokens_W2 }\n",
    "\n",
    "\n",
    "input = { \"witnesses\": [ witness_W1, witness_W2 ] }\n",
    "\n",
    "table = collate(input, output='html2', segmentation=False)\n",
    "print(table)\n",
    "graphSvg = collate(input, output='svg', segmentation=False)\n",
    "print(graphSvg)\n",
    "\n",
    "graph_automaticDictionary = collate(input, output='json', segmentation=False)\n",
    "table_automaticDictionary(graph_automaticDictionary, 'example1')\n",
    "print('external table created!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
